{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install unstructured libmagic python-magic langchain tiktoken faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-google-genai langsmith langserve langgraph python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries and Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(urls=[\n",
    "    \"https://www.siemens.com/global/en/products/services/gbs/operations/digital-solutions.html\",\n",
    "    \"https://www.siemens.com/global/en/products/services/gbs/opportunity-to-cash.html\"\n",
    "])\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20, length_function=len)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docsearch = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing vector index in a local directory\n",
    "import pickle\n",
    "file_path = \"vector_index.pkl\"\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(docsearch, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        docsearch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model='llama2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import chatprompttemplate \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# Create the RAG prompt\n",
    "rag_prompt = ChatPromptTemplate(\n",
    "    input_variables=['context', 'question'], \n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['context', 'question'], \n",
    "                template=\"\"\"You answer questions about the Global business services. \n",
    "                Use only the provided documents as context to answer the question. \n",
    "                Do not use any additional information.\n",
    "                If you don't know the answer, just say that you don't know. Do not use external knowledge. \n",
    "                Use three sentences maximum and keep the answer concise. \n",
    "                Make sure to reference your sources with quotes of the provided context as citations.\n",
    "                \\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\"\n",
    "                )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load in qa_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Read our stories', metadata={'source': 'https://www.siemens.com/global/en/products/services/gbs/operations/digital-solutions.html'}), Document(page_content='Read our stories', metadata={'source': 'https://www.siemens.com/global/en/products/services/gbs/operations/digital-solutions.html'}), Document(page_content='Read our stories', metadata={'source': 'https://www.siemens.com/global/en/products/services/gbs/opportunity-to-cash.html'}), Document(page_content='Read our stories', metadata={'source': 'https://www.siemens.com/global/en/products/services/gbs/opportunity-to-cash.html'})]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is opportunity to cash domain?\"\n",
    "\n",
    "# Find similar documents to the search query\n",
    "docs = docsearch.similarity_search(query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I can infer that \"opportunity to cash\" refers to the process of turning an idea or concept into a viable business opportunity. This domain is likely related to entrepreneurship and innovation, as it involves identifying potential opportunities and turning them into tangible products or services that can be monetized.\n",
      "\n",
      "Here are three sentences that summarize my understanding of the term \"opportunity to cash\" based on the provided context:\n",
      "\n",
      "1. The opportunity to cash refers to the process of transforming an idea or concept into a feasible business opportunity. (Source: Read our stories)\n",
      "2. This domain involves identifying potential opportunities and developing them into tangible products or services that can be monetized. (Source: Read our stories)\n",
      "3. The opportunity to cash is related to entrepreneurship and innovation, as it requires the ability to recognize potential opportunities and bring them to fruition. (Source: Read our stories)\n"
     ]
    }
   ],
   "source": [
    "# Set a response variable to the output of the chain\n",
    "response = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
    "\n",
    "# Display the response\n",
    "print(response[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
